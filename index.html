<!DOCTYPE html>
<html lang="en">
    <head>
        <!-- Hi, this is Nelson. Please DELETE the <script> block below (L6-L13)
          if you use this HTML, otherwise my analytics will track your page. -->
	    <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
             (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                                     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                                    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
            ga('create', 'UA-51640218-1', 'auto');
            ga('send', 'pageview');
        </script>
        <title>Dhanunjaya Varma D</title>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
        <meta property="og:url" content="https://students.iitmandi.ac.in/~s18023" />
	    <meta property="og:title" content="Dhanunjaya Varma D" />
	    <meta property="og:image" content="http://nelsonliu.me/img/dhanunjaya.JPG" />
	    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	    <meta name="author" content="Dhanunjaya">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <link rel="shortcut icon" type="image/png" href="index.ico"/>

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="css/style.css">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <link href='https://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>
    </head>
    <body>
        <div class="container mt-5">
            <div class="row mb-3">
                <div class="col">
                    <h1>Dhanunjaya Varma D</h1>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 col-md-6 order-0 order-xs-0 order-sm-0 order-md-1 order-lg-1">
                    <div class="card mb-3">
                        <img class="card-img-top" src="img/dhanunjaya.JPG" alt="Dhanunjaya Varma">
                        <div class="card-body">
                            <h5 class="card-title">
                                <b>Dhanunjaya Varma D</b>
                            </h5>
                            <p class="card-text">
                                M.S Student
                                </br>
                                School of Computing and Electrical Engineering
                                </br>
                                Indian Institute of Technology Mandi
                                </br>
                            </p>
                        </div>
                    </div>
                </div>
                <div class="col-lg-8 col-md-6 order-1 order-xs-1 order-sm-1 order-md-0 order-lg-0">
                    <p>
                        Hi! I'm a second-year M.S student in computer science at
                        Indian Institute of Technology Mandi's School of Computing and Electrical Engineering (SCEE). I am affiliated with the Multimedia Analytics, Networks and Systems (MANAS) group and I am fortunate to have <a href="http://faculty.iitmandi.ac.in/~padman/" target="_blank">Padmanabhan Rajan</a> as my adviser.
                    </p>
                     <p>
                        My current research focuses on understanding and analysing soundspaces by utilizing background and foreground information using robust PCA. In general, My work in the intersection of deep lerning, machine learning and signal processing (audio signals). I am interested in carrying both theoritical and emperical work in machine learning and it's application in speech/audio, vision and NLP .
                    </p>
                    <p>
                        Previously, I worked as a Software Engineer at Accenture Bangalore, where I was fortunate to have <a href="https://www.linkedin.com/in/shuklaroy/" target="_blank">Shukla</a> and <a href="https://www.linkedin.com/in/satish-guntur-a68b69110/" target="_blank">Satish Guntur</a> as my supervisors. At Accenture I had opportunity to collaborate and work with amazing people across the world.
                    </p>
                </br>
                    <p>
                        I’m happy to help undergraduate students interested in learning coding and machine learning - please feel free to contact me!
                    </p>
                    <!-- <p>
                        Thanks to the support of my research mentors, I was
                        fortunate to begin working on research early in my
                        undergraduate career. I’m happy to help ambitious
                        undergraduate students interested in natural language
                        processing or machine learning get started with
                        research—please feel free to email me!
                    </p> -->
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <p>
                        Email: <a href="mailto: s18023@students.iitmandi.ac.in"> s18023@students.iitmandi.ac.in </a> / <a href="mailto: varma.devalraju@gmail.com"> varma.devalraju@gmail.com </a>
                    </p>
                    <p>
                        Links:
                        [<a href="files/dhanunjaya_cv.pdf" target="_blank">Full CV</a>] [<a href="https://in.linkedin.com/in/dhanunjaya-varma-devalraju-4350105a" target="_blank">LinkedIn</a>] [<a href="https://github.com/dhanunjaya-varma" target="_blank">Github</a>]
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h2>Recent News</h2>
                    <ul>
                        <li>
                            (8/2020) Teaching Assistant for IC272-Data Science III, undergraduate course on Pattern Recognition.
                        </li>
                        <li>
                            (7/2020) Paper on attention-driven projections for soundscape classification, accepted to Interspeech 2020.
                        </li>
                        <li>
                            (5/2020) Paper on soundscape classification using foreground and background, accepted to eusipco 2020.
                        </li>
                        <li>
                            (1/2020) We are organizing/hosting Winter School on Speech and Audio Processing (<a href="https://wissap.github.io/2020/" target="_blank">WiSSAP-2020</a>) at IIT Mandi.
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row" id="publications">
                <div class="col">
                    <h2>Publications</h2>
                    <h3>2020</h3>
                    <ul class="pl">
                        <li>
                            <a href="papers/dhanunjay_attentionDrivenProjections_interspeech20.pdf" target="_blank">
                                <b>Attention-Driven Projections for Soundscape Classification</b>
                            </a>
                            <br/>
                            <b>Dhanunjaya Varma Devalraju</b>,
                            <a href="https://dblp.org/pid/138/1440.html" target="_blank">Muralikrishna H</a>,
                            <a href="http://faculty.iitmandi.ac.in/~padman/" target="_blank">Padmanabhan Rajan</a>,
                            and <a href="http://faculty.iitmandi.ac.in/~addileep/" target="_blank">Dileep A.D</a>.
                            <br/>
                            In <a href="http://www.interspeech2020.org/" target="_blank">
                                <b>
                                    Interspeech</b></a>, 2020.
                            <br/>
                            [<a href="papers/dhanunjay_attentionDrivenProjections_interspeech20.bib" target="_blank">bib</a>]
                            [<a href="#" onclick="$('#dhanunjay_attentionDrivenProjections_interspeech20_abstract').toggle();return false;">abstract</a>]
                            [<a href="papers/2476_highlight_DhanunjayaVarmaDevalraju_Attention-DrivenProjectionsforSoundscapeClassification.mp4" target="_blank">highlight presentation</a>]
                            <!--[<a href="https://quoref-dataset.s3-us-west-2.amazonaws.com/train_and_dev/quoref-train-dev-v0.1.zip" target="_blank">dataset</a>]-->
                            [<a href="https://cloud.iitmandi.ac.in/f/42f1ffc08c624f959a96/?dl=1" target="_blank">code</a>]
                            <div id="dhanunjay_attentionDrivenProjections_interspeech20_abstract" class="abstract" style="display:none;">
                                <p>
                                    Acoustic soundscapes can be made up of background sound events and foreground sound events. Many times, either the background (or the foreground) may provide useful cues in discriminating one soundscape from another. A part of the background or a part of the foreground can be suppressed by using subspace projections. These projections can be learnt by utilising the framework of robust principal component analysis. In this work, audio signals are represented as embeddings from a convolutional neural network, and meta-embeddings are derived using an attention mechanism. This representation enables the use of class-specific projections for effective suppression, leading to good discrimination. Our experimental evaluation demonstrates the effectiveness of the method on standard datasets for acoustic scene classification.
                                </p>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <a href="papers/dhanunjaya_learningtoSeparate_eusipco20.pdf" target="_blank">
                                <b>Learning to Separate: Soundscape Classification using Foreground and Background</b>
                            </a>
                            <br/>
                            <b>Dhanunjaya Varma Devalraju</b>,
                            <a href="http://faculty.iitmandi.ac.in/~padman/" target="_blank">Padmanabhan Rajan</a>,
                            and <a href="http://faculty.iitmandi.ac.in/~addileep/" target="_blank">Dileep A.D</a>.
                            <br/>
                            In <a href="https://eusipco2020.org/" target="_blank">
                                <b>
                                    EUSIPCO</b></a>, 2020.
                            <br/>
                            [<a href="papers/dhanunjaya_learningtoSeparate_eusipco20.bib" target="_blank">bib</a>]
                            [<a href="#" onclick="$('#dhanunjaya_learningtoSeparate_eusipco20_abstract').toggle();return false;">abstract</a>]
                            [<a href="papers/1628_dhanunjaya_LearningToSeparateSoundscapeClassificationUsingForegroundAndBackground.mp4" target="_blank">presentation</a>]
                            <!--[<a href="https://quoref-dataset.s3-us-west-2.amazonaws.com/train_and_dev/quoref-train-dev-v0.1.zip" target="_blank">dataset</a>]-->
                            [<a href="https://cloud.iitmandi.ac.in/f/0f0ccdb3d042414885d7/?dl=1" target="_blank">code</a>]
                            <div id="dhanunjaya_learningtoSeparate_eusipco20_abstract" class="abstract" style="display:none;">
                                <p>
                                    This paper applies the framework of robust principal components analysis (RPCA) to the problem of classifying acoustic soundscapes. RPCA provides a mechanism to decompose a data matrix as the sum of a low-rank matrix and a sparse matrix. In the context of data representing acoustic soundscapes, the low-rank matrix represents the slow-changing background sound events, and the sparse matrix represents the occasional foreground sound events. The data representations are obtained as feature embeddings from pretrained deep convolutional networks. The paper investigates the effectiveness of classifying acoustic soundscapes by using the foreground or background information alone. Further, by using the subspace projection technique of nuisance attribute projection (NAP), the undesired components from the foreground or background are removed. Our results indicate that RPCA and subspace projections indeed provide benefits in improving discrimination for classifying acoustic soundscapes.
                                </p>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <a href="http://dcase.community/documents/challenge2020/technical_reports/DCASE2020_Singh_18.pdf" target="_blank">
                                <b>End2end cnn-based low-complexity Acoustic Scene Classification</b>
                            </a>
                            <br/>
                            <a href="https://sites.google.com/view/arshdeep-singh/home/" target="_blank">Arshdeep singh</a>,
                            <b>Dhanunjaya Varma Devalraju</b>,
                            and <a href="http://faculty.iitmandi.ac.in/~padman/" target="_blank">Padmanabhan Rajan</a>.
                            <br/>
                            In <a href="http://dcase.community/challenge2020/task-acoustic-scene-classification-results-b/" target="_blank">
                                <b>
                                    DCASE 2020 Challenge Technical Report</b></a>, 2020.
                            <br/>
                            [<a href="papers/Singh_IITMandi_task1b_technical_report.bib" target="_blank">bib</a>]
                            [<a href="#" onclick="$('#Singh_IITMandi_task1b_technical_report_abstract').toggle();return false;">abstract</a>]
                            <!--[<a href="https://quoref-dataset.s3-us-west-2.amazonaws.com/train_and_dev/quoref-train-dev-v0.1.zip" target="_blank">dataset</a>]-->
                            [<a href="https://cloud.iitmandi.ac.in/d/bd487a2974f24e6fabf1/" target="_blank">code</a>]
                            <div id="Singh_IITMandi_task1b_technical_report_abstract" class="abstract" style="display:none;">
                                <p>
                                    This technical report describes the IITMandi AudioTeam’s submission for ASC Task 1, Subtask B of DCASE2020 challenge. This report aims to design low-complexity systems for acoustic scene classification. We propose a convolution neural network based endto-end classification framework. The proposed framework learns from raw audio directly. We present performance analysis of various frameworks with model size lesser than 500KB for classification. The three acoustic scenes namely indoor, outdoor and transportation are considered. Our experimental analysis shows that the proposed end-to-end framework, where features are being learned from raw audio directly, with a model size of approx. 77KB gives similar performance on development dataset as that of baseline1 system proposed for the same task.
                                </p>
                            </div>
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col">
                    <h2>Miscellany</h2>
                    <ul>
                     <!--   <li>
                            In my free time, I like to cycle (slowly) and climb
                            (indoors, poorly).
                        </li> -->
                        <li>
                            The source code for this website was borrowed from Nelson Liu (<a href="https://nelsonliu.me/"
                            target="_blank">https://nelsonliu.me</a>)
                        </li>
                    </ul>
                </div>
            </div>
            <footer class="pt-2 my-md-2 pt-md-2 border-top">
                <div class="row justify-content-center">
                    <div class="col-6 col-md text-left align-self-center">
                        <p class="h5 text-muted">
                            © Dhanunjaya, 2020
                        </p>
                    </div>
                    <!-- <div class="col-6 col-md text-right">
                        <a href="https://www.iitmandi.ac.in/Schools/SCEE/index.php" class="image-link">
                            <img class="mr-4" src="img/iitmandi_logo.png" alt="SCEE." height="75" width="100">
                        </a>
                        <a href="http://ai.stanford.edu" class="image-link">
                            <img src="img/stanford_ai_logo.jpg" alt="Stanford AI Lab logo." height="75">
                        </a> 
                    </div> -->
                </div>
            </footer>
        </div>
    </body>
</html>
